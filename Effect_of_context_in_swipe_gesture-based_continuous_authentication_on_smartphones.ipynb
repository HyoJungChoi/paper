{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[paper](https://arxiv.org/pdf/1905.11780v1.pdf)  \n",
    "[dataset&code(matlab)](http://www.oulu.fi/bisg/node/40364)\n",
    "\n",
    "# Effect of context in swipe gesture-based continuous authentication on smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "\n",
    "- 스와이프 동작에서 추출한 터치스크린 및 가속도계 판독을 기반으로 스마트폰 사용자의 지속적인 인증을 수행할 때 컨텍스트를 어떻게 고려해야 하는지를 조사  \n",
    "\n",
    "\n",
    "- 연구는 앉아서 걷고 있는 동안 사전 정의된 읽기 및 탐색 작업을 수행하는 100명의 연구 대상자로 구성된 공개 가능한 HMOG 데이터 세트에 대해 수행  \n",
    "\n",
    "\n",
    "- 인증 오류를 최소화하기 위해 다양한 스마트폰 사용과 인간 활동 시나리오에 컨텍스트별 모델이 필요함  \n",
    "\n",
    "\n",
    "- 또한, 실험 결과는 사용자가 이동 중일 때만 스와이프 제스처 기반 검증 성능을 향상시킨다는 것을 시사\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and related work\n",
    "\n",
    "\n",
    "- CA(Continuous Authentication)는 백그라운드(트랜스패런)에서 (부분) 얼굴 영상, 터치스크린 제스처, 기기 동작, 전력 소비량 등 내장된 센서 및 기기 사용 데이터를 지속적으로 모니터링하여 로그인 후 합법적인 사람이 기기를 사용하고 있는지 확인하는 것을 목적  \n",
    "\n",
    "\n",
    "- 터치 바이오메트릭스 및 CA에 관한 선행연구의 주요 제한사항은 핸드폰 사용과 인간 활동의 맥락이 제대로 고려되지 않았다는 것.  \n",
    "\n",
    "\n",
    "- 터치스크린 제스처와 핸드폰 이동 패턴은 사용자가 검색 또는 읽기(핸드폰 사용)인지, 정지 또는 이동(human activity)인지에 따라 상당한 차이가 있을 것으로 예상할 수 있는데, 이는 CA 시스템이 상황 인식의 필요성을 시사, 또한 핸드폰 사용 컨텍스트에서 인증을 수행해야 하는지 여부도 정의한다.  \n",
    "\n",
    "\n",
    "- 우리는 핸드폰 사용과 human activity 컨텍스트 모두 문지르는 제스처 기반 CA에서 고려되어야 한다는 것을 보여준다. 또한, 우리의 연구 결과는 사용자가 정지해 있을 때 스와이프 기반 CA는 터치 신호에만 의존해야 하며, 핸드폰 이동 패턴을 포함하면 사용자가 이동 중일 때만 CA 성능이 향상된다는 것을 시사\n",
    "\n",
    "\n",
    "![Fig1](./image/Fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology\n",
    "\n",
    ">1) 전화 사용(문서를 읽고 탐색)  \n",
    "(2) 사용자의 신체 활동(앉고 걷는 동안 핸드폰 사용)\n",
    "\n",
    "스마트폰 사용자의 CA에 미치는 영향과 관련된 두 가지 다른 맥락의 분석에 초점을 맞추고 있다.   \n",
    "\n",
    "\n",
    "- 그림 1은 읽기 및 탐색 시나리오에서 터치스크린 제스처로부터 추출된 형상의 분포와 핸드폰 사용자가 앉아 걷고 있는 동안 스와이프 제스처 중 가속도계 신호에서 추출된 형상의 분포를 보여준다.   \n",
    "\n",
    "\n",
    "- 그림 1(a)에 기초하여, 터치 제스처 서로 다른 핸드폰 사용 맥락에서 실제로 유의한 차이를 갖는 것은 명백하다.  \n",
    "\n",
    " \n",
    "- 그림 1(b)은 문지르는 동작 중에 추출된 가속도계 데이터 기능의 분포가 전화 사용자의 신체 활동에 크게 좌우된다는 것을 나타낸다. \n",
    "\n",
    "\n",
    "- 본 연구의 목적은 스마트폰 사용자의 정확한 CA를 위해 각각의 전화 사용 상황 및 각 유형의 인간 활동에 대해 별도의 모델을 교육해야 한다는 것을 보여주는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature extraction\n",
    "\n",
    "- 터치스크린 데이터는 시간 스탬프, 터치 압력 및 스와이프의 x와 y 좌표로 구성  \n",
    "\n",
    "\n",
    "- 가속도계 데이터는 타임스탬프 및 x, y, z 방향의 가속 신호를 포함  \n",
    "\n",
    "\n",
    "- 본 연구에서는 5개 이상의 터치스크린 데이터 포인트가 있는 문지르기 동작이 특징 추출을 위해 고려된다. 이 신호에서 모두 211개의 특징(터치스크린 데이터에서 117개, 가속 데이터에서 94개)을 추출  \n",
    "\n",
    "\n",
    "- 터치 좌표에서 추출된 형상은 2D 데이터뿐만 아니라 평균, 변동, 백분위수, 시간, 길이, 속도, 방향, 제스처 형태 관련 피쳐, x와 y 방향의 스와이프 시작점과 끝점을 포함 (평균, 변동, 백분위수 및 관련 피쳐는 터치 압력 신호에서 계산)   \n",
    "\n",
    "\n",
    "- 가속도계 기능은 스와이프 시 크기 신호와 각 스와이프 전후 0.5초부터 별도로 계산된다. 이러한 특징에는 평균, 최소, 최대, 변동 및 백분위수가 포함된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Anomaly detection\n",
    "\n",
    "- 훈련은 실제 사용자 및 사칭 사용자 데이터의 클래스 간 거리에 기초한 개인별 특성 순위에서 시작된다. 피쳐는 0-1 사이로 먼저 정규화되고 훈련데이터 $S_{train} = \\{f_1, f_2,... \\}$ , 여기서 $f_i$는 피쳐 벡터 i  \n",
    "\n",
    "\n",
    "- 실제 사용자 데이터 $ S_{TrainG} =\\{f_{1G},...,f_{nG}\\} $  사칭 사용자 데이터 $S_{TrainI} = \\{f_{1I},..., f_{nI}\\}$ 로 나타냄  \n",
    "\n",
    "\n",
    "    - 목표는 이 둘 사이에 가장 다른 특징을 찾는 것. 특이치를 제거한 후 두 집합에 대해 각 피쳐의 평균을 별도로 계산하여 이 작업을 수행  \n",
    "\n",
    "- 비율 $(\\lVert mean(f_iG) - mean(f_iI)\\rVert)/mean(f_iG)$을 비교하여 피쳐 순위를 정할 수 있음  \n",
    "\n",
    "\n",
    "- 실제 이상 징후 감지 모델은 예상 최대화(EM) 클러스터링을 사용하여 훈련  \n",
    "\n",
    "\n",
    "- 이 연구에 사용된 모델은 앙상블 분류기여서 여러 분류기들을 훈련시킨다. 이 단계에서는 실제 사용자인 $S_{TRainG}$ 의 훈련 데이터만 사용되며, 이전 단계에서 가장 순위가 높은 40개의 피쳐를 선택하여 분류자를 교육한다.   \n",
    "\n",
    "\n",
    "    - 각 분류기는 두 가지 특징을 사용하여 훈련하는데 첫째 분류기는 가장 높은 것과 두 번째로 높은 것을 사용하고, 둘째 분류기는 두 번째와 세 번째로 높은 것을 사용한다. 각 쌍의 데이터는 EM 알고리즘을 사용하여 클러스터링되며, 새로운 스와이프가 분류되면 각 클러스터 중심까지의 유클리드 거리를 계산  \n",
    "\n",
    "\n",
    "- 분류자는 [10](https://dspace.cvut.cz/bitstream/handle/10467/9443/1998-On-combining-classifiers.pdf?sequence=1)에서 제시한 거리에서 $D = \\Sigma d_i$의 합계를 계산하여 조합    \n",
    "\n",
    "\n",
    "\n",
    "- D에 대한 임계값은 새 스와이프가 정상 또는 이상으로 분류되는지 여부를 정의하며 이 임계값은 훈련 데이터 $S_{TrainG}$에 기초하여 결정  \n",
    "\n",
    "\n",
    "\n",
    "- 거리의 합계의 벡터를 $DG = \\{D_{G1}, . . . , D_{Gn}\\}$, 여기서 $n =\\lVert S_{TrainG} \\rVert$로 표시하자. 임계값은 $D_G$의 ith 백분위수로 간주되고 i 값은 각 사용자별로 최적화되어 EER(Equal Error rate)를 찾는다.\n",
    "\n",
    "\n",
    "\n",
    "- 25개의 순차 관측치 시퀀스와 군집 중심부 $C = \\{D_1, . . , D_{25}\\}$까지의 거리가 분석된다. 불필요한 허위 경보를 피하기 위해 C 값을 순서화하고 최종 분류는 C의 최소값 4개의 평균을 기준으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimental setup and analysis\n",
    "\n",
    "- 가속도계, 자이로스코프 및 자기계 등 다른 센서와 터치 제스처의 데이터를 모두 포함하는 CA에 대해 공개적으로 사용할 수 있는 유일한 다중 모델 데이터셋이기 때문에 HMOG 데이터셋을 고려  \n",
    "\n",
    "\n",
    "- 본 연구는 스와이프 제스처 기반 사용자 인증에 초점을 맞추고 있으므로, 타이핑 시나리오와 관련된 데이터를 폐기, 태핑과 관련된 터치 이벤트는 연구에서 사용되지 않았다.\n",
    "\n",
    "\n",
    "- 실험은 앉아서 문서를 읽는 것(S1)과 걸으면서 읽기(S2)과 앉아서 네비게이팅(S3)과 걸으면서 네비게이팅(S4)의 네 가지 시나리오를 바탕  \n",
    "\n",
    "\n",
    "- 각 작업은 네 번의 세션 동안 수행되었다. 처음 두 세션의 스와이프 제스처 데이터는 훈련에 사용되고 나머지 두 세션은 테스트에 사용된다. 실험은 터치스크린, 가속도계 및 둘 모두의 조합의 세 가지 특징 세트를 사용하여 수행\n",
    "\n",
    "\n",
    "![T11905](./image/T11905.png)\n",
    "\n",
    "- 상황별 모델은 동일한 시나리오에서 다른 세션의 데이터에 대해 훈련되고 테스트된다. 일반 모델은 모든 시나리오의 데이터를 사용하여 훈련하고 각 개별 시나리오에서 차례로 시험한다. 그 결과에 따르면, 상황별 모델을 사용할 때 그 결과는 훨씬 더 좋다.  \n",
    "\n",
    "\n",
    "    - 특히 상황별 인증 모델이 있는 경우 S1에서는 평균 EER가 21.3%에서 11.7%로, S2에서는 15.8%에서 7.0%로 떨어지기 때문에 읽는 시나리오에서는 특정 모델의 혜택을 받는다.  \n",
    "    \n",
    "    \n",
    "    - 실제로, 터치 및 모션 기능의 융합을 사용하여 보행 시나리오에 대한 최상의 EER를 얻는 반면, 앉은 시나리오에 대한 최상의 EER는 터치 스크린 기능만을 사용하여 얻는 것을 표 1에서 확인할 수 있다.  \n",
    "    \n",
    "    \n",
    "    \n",
    "    - 네비게이션 시나리오는 다른 방향의 스와이프를 포함하고 있는 반면에 읽는 시나리오에서는 주로 수직 방향을 포함하기 때문에 CA 관점에서 읽는 시나리오보다 더 어렵다는 것을 보여준다. \n",
    "    \n",
    "    \n",
    "    - 실제로 수평 스와이프가 제거된 S3 데이터로 추가 실험을 했다. 터치 기능의 EER는 21.5%에서 17.2%로 떨어졌는데, 이는 수직 스와이프가 피실험자들 사이에서 더 독특한 변화를 포함하고 있음을 시사\n",
    "    \n",
    "\n",
    "\n",
    "![T21905](./image/T21905.png)\n",
    "\n",
    "- 표 2는 훈련과정에서 핸드폰 사용과 신체 활동 상황을 모두 고려하는 것의 중요성을 보여준다.  \n",
    "\n",
    "\n",
    "- 표 2는 핸드폰 사용 컨텍스트가 동일하게 유지되는 동안 CA 모델이 한가지 신체적 활동으로 훈련하고 다른 활동으로 테스트 될 때 평균 EER를 나타낸다.  \n",
    "\n",
    "\n",
    "    - 예를 들어, EER은 걸으면서 읽기(S2) 대신 걸으면서 네비게이팅(S4)를 훈련할 때 7.0%에서 20.9%로 뛰기 때문에 핸드폰 사용 컨텍스트는 오류율에 큰 영향을 미친다.  \n",
    "    \n",
    "    \n",
    "    - 마찬가지로 걸으면서 읽기(S2) 대신 앉은 채로 읽기(S1)를 훈련을 할 때 EER은 7.0%에서 12.2%로 증가한다. 일반적으로, 핸드폰 사용 컨텍스트는 사용자의 신체 활동보다 오류율에 더 큰 영향을 미친다는 것을 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusions and future work\n",
    "\n",
    "- 본 연구는 스와이프 제스처 기반 연속 인증에서 컨텍스트의 역할을 조사  \n",
    "\n",
    "\n",
    "- 서로 다른 응용 프로그램이나 태스크는 그들만의 특정한 모델을 필요로 할 뿐만 아니라 다른 인간 활동도 필요로 한다.   \n",
    "\n",
    "\n",
    "- 실험에 따르면 사용자가 정지해 있는 경우 스와이프 기반 검증에 터치 기능만 사용해야 하며 사용자가 이동할 때 터치스크린과 가속도계 신호에서 추출된 형상의 조합을 사용해야 한다.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

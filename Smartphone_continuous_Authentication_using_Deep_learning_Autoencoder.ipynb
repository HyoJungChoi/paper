{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countinuous Authentication using Deep learning Autoencoder\n",
    "\n",
    "[paper](https://www.ucalgary.ca/pst2017/files/pst2017/paper-92.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**continuous Authentication**: 신원확인 및 사이버 보안 보호를 지속적으로 제공하기 위한 검증 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "- 딥러닝 오토인코더를 기반으로한 접근법 제안   \n",
    "\n",
    "\n",
    "- 차원 피처 수와 재인증 시간 간 (차원 수가 커지면 감소)의 균형을 논의    \n",
    "\n",
    "\n",
    "- 각 특정 컨텍스트에 필요한 정확도와 유용성 간의 최적의 절충을 찾기 위한 아키텍처의 깊이, 모델 및 훈련 데이터셋의 길이, 다시 구축하기 전에 경과된 시간 등에 대해 논의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- implicit authentication은 1차 인증방법 또는 더 높은 보증을 위한 보조 사기 지표로 사용 될 수 있다.  \n",
    "\n",
    "> implicit authentication: 지문, PIN, 패턴 잠금 ...  \n",
    "\n",
    "- 이 논문은 스마트폰과 상호작용 하면서 사용자별 동작 패턴에 의존하는 새로운 연속 생체 인증 시스템을 제안한다.    \n",
    "\n",
    "\n",
    "> 테스트 된 실제 시나리오에선 2.2%(EER)이다.  \n",
    "    \n",
    "> 클라우드 기반이기 때문에 장치에 계산 부담이 감소했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  기능 추출 프로세스는 오토인코더 라는 딥러닝 기술을 기반으로 한다.  \n",
    "![autoencoder](https://user-images.githubusercontent.com/56706812/78358825-cbcb8380-75ee-11ea-932e-dc426127beb4.png)\n",
    "- 두 개의 공개 데이터 세트를 사용하며, 하나는 실험실 환경에서 수집되고 하나는 실제 시나리오에서 크라우드소싱된 집합이다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder는 데이터를 효율적으로 압축하고 인코딩하는 방법을 학습한 후, 감소된 인코딩된 표현에서 가능한 한 원래의 입력에 가까운 표현으로 데이터를 재구성하는 방법을 학습하는 비지도 인공 신경망이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biometric Authentication System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 사용자는 음성 또는 동작과 같은 특성 패턴을 설명하는 기능 그룹에 의해 식별된다.  \n",
    "  \n",
    "  \n",
    "- BAS(생체 인증 시스템)는 사용자 인식을 위해 생체 인식 데이터를 캡처하고 처리한다.  \n",
    "\n",
    "\n",
    "- 요즘에는 환경, 위치 및 사용자 별 동작 정보와 같은 생체 인식 데이터를 캡처 할 수있는 많은 다른 센서가 스마트 폰에 통합되었다.\n",
    "\n",
    "\n",
    "\n",
    "![enroll](https://user-images.githubusercontent.com/56706812/78358807-c53d0c00-75ee-11ea-999a-2b2ced1fc295.png)\n",
    "\n",
    "- a) 생체 인식 샘플은 사용자 유효성 검사에 사용할 수 있는 사용자 별 패턴을 나타내는 feature 벡터에서 capture 및 process.  \n",
    "\n",
    "\n",
    "\n",
    "- b) 새 데이터 샘플(예: 인증 요청)이 시스템에 제공된다.    \n",
    "\n",
    "\n",
    "\n",
    "- 인증 시스템이 초기화되면 다수의 인스턴스를 캡처하여 b로 전송하며, 여기서 분류 모델이 구축된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dist](https://user-images.githubusercontent.com/56706812/78358867-dede5380-75ee-11ea-84ff-9b50c5da6ac0.png)\n",
    "\n",
    "- 다른 개인에 속하는 샘플은 예시된 바와 같이 다른 경기 점수 분포를 갖게 된다.  \n",
    "\n",
    "\n",
    "- 다모드(multimodal)의 생체 인식 시스템은 시스템에서 검출 속도를 높이는 수단으로 제안되었지만 접근 방식의 계산 부담은 상당히 증가하고 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (evaluate the accuracy and precision of the proposed BAS)\n",
    "\n",
    "![eval1](https://user-images.githubusercontent.com/56706812/78358886-e7cf2500-75ee-11ea-9763-a1311ebe3334.png)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "![eval2](https://user-images.githubusercontent.com/56706812/78358887-e9005200-75ee-11ea-926a-91d749301e3a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 각 개인의 보유패턴을 기반으로 스마트 폰에 대한 지속적인 인증 생체 인식 시스템을 제안한다.   \n",
    "\n",
    "\n",
    "- **이전 연구들과는 다르게 가속도계 센서의 3D(x,y,z) 만을 이용하여 계산 부담을 덜어준다.**  \n",
    "\n",
    "\n",
    "- **또한 우리는 클라우드에 enroll 및 recognition 단계를 추가로 구현하여 디바이스에 캡처 모듈만 남겨둔다.**  \n",
    "\n",
    "\n",
    "- 기능 추출 프로세스는 딥러닝 오토인코더를 기반으로 하며, 이를 통해ㅜ 경쟁력 있는 정확도를 달성할 수 있었다.    \n",
    "\n",
    "\n",
    "- 모델이 추정되면 유효성 검사 세트의 각 인스턴스들은 MSE를 계산하여 처리 되며, 우리는 이 값을 match score로 나타낸다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 결정 임계값(DT) 는   \n",
    "\n",
    "$$ DT = average(e) + \\phi standard deviation(e)$$  \n",
    "\n",
    "- 여기서 φ은 고려된 정규 분포의 백분율 신뢰 구간이다. match score가 DT보다 높으면 인증 요청 인스턴스가 fraud로 분류된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델에서 입력 단위 수는 window size와 같고 3D 가속도계 데이터의 차원수와 동일하다.  \n",
    "![auto1](https://user-images.githubusercontent.com/56706812/78358931-fddce580-75ee-11ea-8326-2736de1d9e05.png)\n",
    "\n",
    "\n",
    "\n",
    "- the input is the observation vector a = ax1, ay1, az1, . . . , axn, ayn, azn and the output is:\n",
    "\n",
    "$$ u(\\alpha)=h_u(W_u\\alpha + b_u)   , W_u∈R^{3nx3n},  b_u ∈R^{3n} $$  \n",
    "\n",
    "- $\\ h_u$ 는 Tanh 활성화 함수이다.    \n",
    "\n",
    "\n",
    "\n",
    "- 인코딩 단계에서는 input $\\alpha$는 $u(\\alpha)$로 나타내며, 디코딩 단계에서 변환이 출력된 표현으로 $\\hat \\alpha$로 나타낸다.  \n",
    "\n",
    "$$ \\hat\\alpha = h_d[W_d{u(\\alpha)} + b_d]$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인코딩 행렬이 디코딩 행렬의 전치 행렬인 아키텍처를 사용하여 자유도를 제한한다. (i.e. $ W_d = W_u ^T$)  \n",
    "\n",
    "\n",
    "\n",
    "- 다중 레이어 아키텍처에서, 인코더와 디코더는 대칭적으로 쌓여 있는데, 여기서 k번째의 인코더의 출력은 k + 1번째 인코더의 입력이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![cloud](https://user-images.githubusercontent.com/56706812/78358954-09c8a780-75ef-11ea-83f4-6961196a2a6f.png)\n",
    "\n",
    "- 클라우드 플랫폼의 상당한 발전과 스마트폰과 클라우드 리소스 간의 저렴한 데이터 연결의 가용성으로 인해 우리는 더욱 정교한 애플리케이션을 구현할 수 있다.  \n",
    "\n",
    "\n",
    "- 그림 4는 제안된 접근방식의 분산형 구조를 보여준다.  \n",
    "\n",
    "\n",
    "- 캡쳐 서비스는 지속적으로 데이터를 샘플링한다. 각 인스턴스에 고유한 ID를 할당하여 클라우드 미들웨어로 전송한다.  \n",
    "\n",
    "\n",
    "- Sys 서비스는 개인이 장치를 사용할 때 n/fs마다 플래스크 서버에서 현재 상태(즉, 합법적 상태 또는 사기적 상태)를 검색한다.\n",
    "\n",
    "> 유효한 인스턴스로 분류됨: 인스턴스가 훈련 서비스로 전송됨    \n",
    "\n",
    "> 부정행위로 분류된 인스턴스: 클라우드 저장소의 장치 상태가 부정행위로 업데이트되고 인스턴스는 폐기된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is window size?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 패킷의 수를 window size라고 한다. window size 제한은 수신 컴퓨터가 데이터 패킷을 처리할 수 있는 속도와 버퍼 용량에 따라 다르다.\n",
    "\n",
    "패킷: 패킷은 정보 기술에서 패킷 방식의 컴퓨터 네트워크가 전달하는 데이터의 형식화된 블록이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is instance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 컴퓨터 프로그램의 런타임에 존재하는 어떤 물체의 구체적인 발생이다. 형식적으로, \"인스턴스\"는 각각 특정한 값(실현)이기 때문에 \"객체\"와 동의어로, 이것들은 인스턴스 객체라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biometric Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**제어된 랩 환경의 샘플**\n",
    "\n",
    "\n",
    "> 실험실 환경 데이터 세트: 100Hz의 샘플링 주파수를 가진 100명의 자원봉사자의 스마트폰에서 3D 가속도계 데이터를 수집했다.  \n",
    "\n",
    "데이터는 지도 읽기, 쓰기 및 탐색의 세 가지 활동 시나리오에서 샘플링되었다.  \n",
    "\n",
    "> 두 가지 신체 운동 조건: 앉기, 걷기  \n",
    "\n",
    "각 자원봉사자는 각 운동 조건에 대해 동일한 비율의 세션으로 각 활동에 대해 24개의 세션, 8개의 세션을 수행했습니다. \n",
    "각 자원봉사자는 총 6시간의 데이터를 제공했다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**실제 시나리오 데이터 집합**  \n",
    "\n",
    "\n",
    "\n",
    "- 우리는 20 명의 자원 봉사자의 스마트 폰에 센서로 며칠 동안 지속적으로 캡처 된 3D 가속도계 데이터에 액세스 했다.  \n",
    "\n",
    "\n",
    "- 데이터 세트는 개인이 장치를 사용하는 시기에 대한 정보를 제공하여 나머지 샘플을 폐기할 수 있도록 한다.  \n",
    "\n",
    "\n",
    "- 데이터는 매 분마다 20초 연속으로 200Hz 또는 100Hz의 샘플링 주파수로 수집되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of the detection algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시험 데이터 세트에는 훈련 데이터 세트와 동일한 활동 및 동작 조건의 비율을 가진 동일한 사용자의 6개 세션과 두 번째 사용자(사기 사용자)의 6개 세션의 샘플이 포함된다.  \n",
    "\n",
    "\n",
    "- training dataset는 30분간의 인스턴스, validation dataset은 10분 test dataset은 20분이 포함된다.  \n",
    "\n",
    "\n",
    "- 많은 실험을 실행한 후 우리는 window size를 500개의 샘플로 설정했고, 각 hidden layer의 숨겨진 units는 1500개에 상당하며, 이 값들은 재인증 시간과 정확도 사이의 최선의 절충을 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![match1](https://user-images.githubusercontent.com/56706812/78358973-15b46980-75ef-11ea-8599-195060402759.png)\n",
    "\n",
    "- 그림 6은 단일 공격 시나리오에 예측된 일치 점수 분포를 보여 주며, 동일한 시뮬레이션을 10회 실행하여 얻은 결과의 평균을 표시한다.\n",
    " \n",
    "\n",
    "\n",
    "- x차원의 데이터만 고려했을 때 입력단위가 더 적은 경우, legitimate와 fraudulent 매치 점수 분포는 꼬리가 크고, 그 사이에 명확한 분리가 없는 경우를 관찰할 수 있다.   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 세 축의 샘플을 고려할 때 둘 사이의 분리가 더 정의되어 더 커진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![match](https://user-images.githubusercontent.com/56706812/78358977-16e59680-75ef-11ea-835c-b76f6c46453c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 재인증 시간은 window size에 따라 다르기 때문에(섹션 IV에서 살펴본 바와 같이), 증가시킨다는 것은 사용자의 유효성을 덜 자주 확인하는 것을 의미한다.  \n",
    "\n",
    "\n",
    "- x차원의 데이터만 사용할 경우 그림 7과 같이 두 분포 사이의 명확한 분리를 얻으려면 적어도 1500개의 표본이 필요하다. 그 결과 180초의 재인증 시간이 발생한다.   \n",
    "\n",
    "\n",
    "- 스마트폰 세션의 평균 지속시간이 72초이므로 실제 시나리오에서는 이러한 재인증 경과시간이 적절하지 않다.   \n",
    "\n",
    "\n",
    "\n",
    "- 그림 6의 분석에서 우리는 500개의 표본의 창 크기를 사용했기 때문에, 본 연구의 재인증 시간은 20초이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![far](https://user-images.githubusercontent.com/56706812/78359009-2664df80-75ef-11ea-9f31-2783b5ae1641.png)\n",
    "\n",
    "- 5 개의 hidden layer를 포함하여 모델을 사용할 때 ERR이 5.9 %에서 4.5 %로 감소하는 것을 관찰 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![table1](https://user-images.githubusercontent.com/56706812/78359029-311f7480-75ef-11ea-987c-db218c25f58d.png)\n",
    "\n",
    "모델을 재구축하기 전에 처리된 스트림 길이(byte)가 15, 30분에서 60분 사이에 다를 때 접근의 정확성을 시험한다. 훈련 및 검증 데이터 세트는 합법적인 사용자의 샘플만 포함한다.   \n",
    "\n",
    "\n",
    "test 데이터 세트에는 합법적인 사용자와 fraud 사용자로부터 샘플이 포함되며, 각 데이터 세트의 인스턴스 비율이 동일하다. 훈련 데이터 세트에는 60분 기간의 인스턴스, 30분 동안의 검증데이터 세트 및 60분 동안의 테스트 데이터 세트가 포함된다.  \n",
    "\n",
    "- 모델을 다시 빌드하기 전에 처리된 인스턴스 수가 증가함에 따라 정확도가 감소하는 세 가지 아키텍처 모두를 관찰할 수 있다.  \n",
    "\n",
    "\n",
    "\n",
    "- 모델을 다시 빌드하기 전에 처리된 스트림의 길이가 15분이면 hidden layer 수가 증가함에 따라 ERR이 감소하여 5개의 hidden layer가 2.2%의 ERR을 포함하는 모델을 달성한다.  \n",
    "\n",
    "\n",
    "- 이러한 개선은 처리된 인스턴스 수가 증가함에 따라 사라지는 경향이 있으며, 스트림 길이가 60분일 때 세 가지 아키텍처가 동일한 ERR을 표시한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table2](https://user-images.githubusercontent.com/56706812/78359035-3250a180-75ef-11ea-89fd-70ff324539a1.png)\n",
    "\n",
    "- 훈련 데이터 세트를 60분에서 90분으로 늘릴 때는 오직 하나의 숨겨진 계층을 가진 모델만이 더 나은 정확도를 보여준다.  \n",
    "\n",
    "\n",
    "- 5개의 숨겨진 레이어를 포함하는 모델은 훈련 데이터 세트의 길이에 관계없이 최고의 정확도를 달성한다.    \n",
    "\n",
    "\n",
    "- **따라서 실제 시나리오에서는 높은 정확도를 달성하기 위해 더 많은 수의 숨겨진 계층, 더 긴 훈련 데이터셋을 포함하는 아키텍처를 사용하여 모델을 더 자주 재구성해야 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![table3](https://user-images.githubusercontent.com/56706812/78359037-32e93800-75ef-11ea-8f10-db7b579d2834.png)\n",
    "\n",
    "- 우리는 교육 데이터셋의 지속시간을 증가시킬 때 모델을 교육하는 시간이 거의 비례적으로 증가하는 것을 관찰한다.   \n",
    "\n",
    "\n",
    "\n",
    "- 숨겨진 층의 수를 1개에서 3개로 증가시킬 때, 모델을 훈련하는 시간은 약 2배, 숨겨진 층의 수가 5개일 때는 대략 3배이다.  \n",
    "\n",
    "훈련 시간과 인증 시간의 차이가 크면 각 작업에 대해 서로 다른 하드웨어 사양의 VM을 사용하고, 컴퓨팅 성능이 더 높은 노드에서 훈련 프로세스를 구현하는 것을 제안한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 사용자의 특정 동작 패턴을 이용함으로써 fraud 액세스를 탐지할 수 있는 스마트폰에 대해 클라우드 기반의 연속 인증 생체 인식 시스템을 제안한다.\n",
    "\n",
    "\n",
    "- 우리는 더 많은 수의 hidden layer를 가진 오토인코더 구조가 fraud 매치 점수 분포와 legitimate 매치 점수 분포 사이의 더 높은 분리를 달성한다는 것을 보여주었다.  \n",
    "\n",
    "\n",
    "\n",
    "- 모바일 플랫폼의 고유한 요구 사항을 충족하기 위해 탐지 프로세스는 소수의 생체 인식 기능에 의존하며 우리는 계산 부담을 스마트폰에서 클라우드로 이동시킨다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

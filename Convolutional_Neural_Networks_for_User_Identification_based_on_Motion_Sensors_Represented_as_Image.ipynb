{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[paper](https://arxiv.org/pdf/1912.03760.pdf)\n",
    "\n",
    "# Convolutional Neural Networks for User Identificationbased on Motion Sensors Represented as Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "- 본 논문에서는 사용자가 화면에서 수행하는 한 번의 탭 제스처 중 가속도계와 자이로스코프가 기록한 동작 신호를 분석하여 스마트폰 사용자 식별을 위한 딥러닝 접근법을 제안  \n",
    "\n",
    "\n",
    "- 동작 센서로부터 분리된 3축 신호를 다극성 사용자 분류를 위해 pre-trained convolutional neural network(CNN)에 입력으로 제공되는 그레이 스케일 영상 표현으로 변환  \n",
    "\n",
    "\n",
    "- 우리는 CNN 기능에 기반한 우리의 식별 시스템을 handcrafted 피쳐를 사용하는 시스템과 RNN 기능을 사용하는 두 개의 기준 시스템과 비교한다. 모든 시스템은 동일한 분류기, 즉 SVM을 기반으로 한다.  \n",
    "\n",
    "\n",
    "- CNN 모델이 멀티 클래스 사용자 분류에서 89.75%의 최고 정확도와 few-shot 사용자 인식에서 96.72%의 최고 정확도  \n",
    "\n",
    "\n",
    "- 결론적으로, 시스템이 두 기준선보다 더 나은 일반화 능력을 가지고 있어 실용적으로 사용할 준비 되어 있다 믿음\n",
    "\n",
    "\n",
    "**handcrafted feature?**  \n",
    "\n",
    "머신러닝에서는 사람이 직접 특징을 정해주는데 그 특징을 handcrafted feature라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- 우리의 접근방식은 가속도계와 자이로스코프에서 분리된 3축 신호를 CNN의 입력으로 제공할 수 있는 그레이 스케일의 영상 표현으로 변환하는 것에 기초  \n",
    "\n",
    "\n",
    "- 우리의 이미지 표현은 변형된 버전의 de Bruijn Sequence를 사용하여 6개의 1차원(1D) 신호를 반복하는 것에 기초  \n",
    "\n",
    "\n",
    "- 표준 지문이나 얼굴 인증 시스템에서 사용하는 등록 프로세스와 시간 면에서 유사하게 빠른 등록 프로세스(화면상의 20 탭이면 충분)를 가능하게 하기 위해 사용자당 20개의 샘플이 있는 few-shot learning을 고려  \n",
    "\n",
    "\n",
    "- 실험을 수행하기 위해, 우리는 초기 세션에서 짧은 신호를 추출하고 사용자를 반으로 나누면서 예비 다급 사용자 분류 실험에서는 전반을, 사용자 식별 실험에서는 후반을 사용하여 HMOG 데이터 세트를 수정  \n",
    "\n",
    "\n",
    "- CNN 기능에 기반한 SVM은 사용자 식별 실험에서 두 기준선을 모두 능가하는 높은 일반화 capacity 을 입증  \n",
    "\n",
    "\n",
    "- 96.72%의 정확도로 CNN 기능에 기반한 SVM은 실용적인 사용을 위한 실행 가능한 솔루션으로 보인다.\n",
    "\n",
    "\n",
    ">• CNN의 입력으로 유용하도록 특별히 설계된 이산형 신호의 새로운 그레이 스케일의 이미지 표현을 제안  \n",
    "• 우리는 few-shot 사용자 식별을 위한 유용한 임베딩을 얻기 위해 다중 클래스 사용자 분류 작업에 대해 CNN을 사전 교육할 것을 제안  \n",
    "• CNN 임베딩에 기반한 우리의 방식이 handcrafted feature에 기반한 기계학습 방법과 RNN 임베딩에 기반한 딥러닝 방법 모두를 능가한다는 것을 보여주는 비교 실험을 실시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what is few shot learning?**\n",
    "\n",
    "이름에서 알 수 있듯이, 적은 양의 학습은 많은 양의 데이터를 사용하는 일반적인 관행과는 달리 매우 적은 양의 훈련 데이터를 학습 모델에 공급하는 관행을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "\n",
    "- 우리는 다른 접근법을 취하여 가속도계와 자이로스코프가 기록한 운동신호의 깊은 임베딩(deep intending)을 얻기 위해 CNN을 사용할 것을 제안  \n",
    "\n",
    "\n",
    "- 우리의 사용자 식별 실험에서 보여지듯이, 우리 CNN이 학습한 임베딩은 기준선 RNN이 학습한 임베딩보다 더 견고하여 상당한 성능 향상을 이끌어 낸다.   \n",
    "\n",
    "\n",
    "- 키 스트로크 역학을 기반으로 한 사용자를 인식하기 위해 RNN을 사용하는 반면, 우리는 화면 탭 동안에 기록된 동작 데이터를 기반으로 사용자를 인식하기 위해 CNN을 사용하는 것을 제안한다  \n",
    "\n",
    "\n",
    "- 우리의 방법은 한 번의 탭 제스처 동안 기록된 1.5초의 동작 신호를 기반으로 사용자를 식별하도록 설계되어 있다. 게다가, 우리의 방법은 사용자 등록 단계에서 20개의 샘플(탭)만 필요로 한다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "- 그림 1과 같이, 우리의 첫 번째 단계는 스마트폰의 가속도계와 자이로스코프 센서에서 획득한 이산 신호를 그레이 스케일의 이미지로 바꾸는 것  \n",
    "\n",
    "\n",
    "- 동작 센서의 세 축에 대해 보고된 신호의 길이는 동일하지만, 서로 다른 동작 센서에 의해 보고된 신호의 길이는 다를 수 있다. 따라서 우리는 운동신호를 일정한 길이로 정규화 시켜야 한다.  \n",
    "\n",
    "\n",
    "    - 100Hz로 1.5초간 신호를 기록하기 때문에 150개의 이산값으로 형성될 것으로 예상  \n",
    "\n",
    "\n",
    "    - 신호의 크기를 조정한 후 각 값이 양수가 되도록 최소 크기를 뺀다. 각 신호는 이제 150개의 양의 성분의 벡터가 된다.  \n",
    "    \n",
    "    \n",
    "    - 한 축에 사영된 운동이 다른 축에 사영된 운동보다 훨씬 더 클 경우, 우리는 독립적으로 L2-norm을 사용하여 벡터를 정상화한다. 그런 다음 그레이 스케일 영상에 사용할 수 있는 값의 전체 범위를 사용하기 위해 [0, 255] 간격으로 값을 재조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig11912](./image/Fig11912.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 먼저 0에서 5까지의 숫자를 연결하여 생성된 순서에서 우리의 신호를 식별한다. 크기 k의 알파벳 $\\Sigma$(신호수, 여기선 k = 6)에 있는 De Brujin 시퀀스 n(우리의 경우 tuples의 길이, n = 3) \n",
    "\n",
    "\n",
    "- $\\Sigma$=$\\{0,1,2,3,4,5\\}$ ,n=triplet\n",
    "\n",
    "\n",
    "\n",
    "-  n = 3과 k = 6에 대한 de Brujin 시퀀스의 최소 길이는 218이지만, 우리는 25의 짧은 시퀀스를 얻는다.  \n",
    "\n",
    "\n",
    "     - 시퀀스는 0, 1, 2, 3, 4, 5, 2, 4, 5, 4, 5, 1, 3, 4, 1, 2, 5, 3, 4, 5, 0, 0, 5, 0, 5, 1, 3, 4.\n",
    "     \n",
    "     - 생성된 시퀀스를 이용하여 25 × 150 픽셀의 그레이 스케일의 영상표현을 구축한다. 그림 2에서는 무작위로 선택한 기록 세션의 세트에 대해 구성된 이미지 표현(각각 1.5초 길이)을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig21912](./image/Fig21912.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-based Feature Extraction\n",
    "\n",
    "- 콘볼루션 신경망은 콘볼루션 층을 이용하여 영상을 효율적으로 처리하도록 설계된 특정한 형태의 feed-forward 신경망  \n",
    "\n",
    "\n",
    "-  ImageNet의 pre-trained CNN 모델을 다른 모델과 같이 고려하는 대신, 모델을 사용자 식별 작업으로 옮기기 전에 모델을 훈련시키기 위해서 다중 클래스 사용자 분류 작업을 고안한다. 이것은 우리의 CNN 모델이 같은 종류의 입력 이미지에 특별히 적응하도록 보장한다.\n",
    "\n",
    "\n",
    "**pre-trained?**  \n",
    "\n",
    "비슷한 문제를 해결하기 위해 다른 누군가가 만든 모델  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 우리는 서로 다른 깊이의 CNN 아키텍처를 3개 제안한다. 각 아키텍처는 서로 다른 수의 콘볼루션(conv) 계층으로 구성되며, 그 뒤에 고정된 수의 완전 연결(fc) 계층이 뒤따른다.  \n",
    "\n",
    "\n",
    "- Softmax 활성화가 있는 분류 계층을 제외한 모든 계층에서 활성화 기능으로 ReLU(Recified Linear Unit)를 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**첫번째 CNN architecture**  \n",
    "\n",
    "- 6개의 레이어, 즉 3개의 conv 레이어, 2개의 fc 레이어, 그리고 Softmax 분류 레이어. 각 콘볼루션 층에는 풀 크기가 2 × 2인 max-pooling 층이 뒤따른다. \n",
    "\n",
    "\n",
    "    - 첫 번째 conv 레이어는 32개의 필터로 구성, 3 × 3 수용영역. 필터는 stride=1, zero-padding\n",
    "    \n",
    "    - 두 번째 conv 레이어는 64개의 필터로 구성, 수용영역 3 × 3 \n",
    "    \n",
    "    - 세 번째 conv 레이어는 128개의 필터로 구성, 수용영역 3 × 3 \n",
    "    \n",
    "    \n",
    "- 활성화 맵은 공간 차원을 보존하기 위해 제로 패딩되어 있다. \n",
    "\n",
    "    - 세 번째 conv 층은 각각 256개의 뉴런으로 이루어진 2개의 fc 층으로 이어진다. 우리는 각 fc 레이어에 드롭아웃을 사용하며, 드롭아웃 rate은 0.4로 설정된다.\n",
    "    \n",
    "    \n",
    "- 마지막 층은 50개의 뉴런을 가진 fc 층으로, 우리의 다급 사용자 분류 과제의 클래스(사용자) 수에 해당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**두 번째 CNN architecture**\n",
    "\n",
    "- 9개의 레이어, 즉 6개의 conv 레이어, 2개의 fc 레이어, 그리고 Softmax 분류 레이어. CNN의 9단 구조는 각 conv 계층을 정확히 한 번 복제하여 6단 cnn 아키텍처에서 파생되었다.   \n",
    "\n",
    "\n",
    "    - 1층과 2층은 32개의 필터\n",
    "    - 3층과 4층은 64개의 필터\n",
    "    - 5층과 6층은 128개의 필터\n",
    "    \n",
    "    \n",
    "- 9층 CNN에서는 2층, 4층, 6층만 풀 크기가 2×2인 max-pooling로 이어진다. 다른 계층과 파라미터는 6계층 CNN 아키텍처와 동일하다.  \n",
    "\n",
    "\n",
    "**세 번째 CNN architecture**  \n",
    "\n",
    "- 가장 깊은 아키텍쳐로 12개의 레이어, 즉 9개의 conv 레이어, 2개의 fc 레이어, 그리고 Softmax 분류 레이어  \n",
    "\n",
    "\n",
    "- 12층 CNN 아키텍처는 각 conv 계층을 복제하여 6층 CNN 아키텍처에서 파생된다.\n",
    "\n",
    "\n",
    "    - 처음 3개의 conv 레이어는 32개의 필터\n",
    "    - 다음 3개의 conv 레이어는 64개의 필터\n",
    "    - 마지막 3개의 conv 레이어는 128개의 필터  \n",
    "    \n",
    "    \n",
    "- 3층, 6층, 9층짜리 conv 층만 최대 풀링 층이 뒤따른다.  \n",
    "\n",
    "\n",
    "> 모든 모델은 범주형 교차 엔트로피 손실 함수와 함께 Adam 최적화 도구를 사용하여 훈련한다.   \n",
    "\n",
    "\n",
    "> 최고의 CNN 모델을 찾은 후 소프트맥스 레이어를 제거하고 마지막 남은 fc 레이어의 활성화 맵을 피쳐 벡터(딥 임베딩)로 사용한다. 마지막 fc 층이 256개의 뉴런으로 구성되어 있다는 것을 고려하면, 우리는 256차원 임베딩을 얻을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Few-shot User Identification\n",
    "\n",
    "- 현실적인 사용자 식별 시나리오에서는 바이너리 분류 모델을 구축하기 위해 공격자(임프로젝터)가 수행하는 샘플 집합에 접근할 수 없다.  \n",
    "\n",
    "\n",
    "\n",
    "- 정당한 사용자나 공격자에게 속하지 않는 데이터 샘플 풀을 사용하여 이진 분류기를 훈련할 수 있으며 이항 분류 작업에서 양수 표본은 올바른 사용자에게 속하고 음수 표본은 공격자에 속한다.  \n",
    "\n",
    "\n",
    "- 우리는 SVM 이진 분류기를 사용한다. 이진 분류 문제의 경우, SVM과 같은 커널 분류자 은 한 클래스에 속하는 예에 양의 라벨(+1)을, 다른 클래스에 속하는 예에는 음의 라벨(-1)을 할당하는 차별 함수 g를 찾는다. 함수 g는 feature space에서 선형이며 다음과 같이 표현할 수 있다.\n",
    "\n",
    "$$ g(x) = sign(<w,x> + b) $$\n",
    "\n",
    "- 여기서 x는 featrue vector, w와 b는 weight vector, <,>는 dot product이며 SVM은 마진을 최대화 하는 w,b를 찾는것을 목표로 한다.  \n",
    "\n",
    "\n",
    "$$ min\\frac{1}{n}\\sum_{i=1}^n[1-y_i(<w,x_i> + b)]_+ + C\\lvert\\lvert w \\rvert\\rvert^2 $$\n",
    "\n",
    "- n은 훈련 표본의 수, yi는 훈련 예제 xi의 라벨(+1 또는 -1)이고, C는 정규화 매개변수, [x]+ = max{x, 0}, $\\lvert\\lvert . \\rvert\\rvert^2$는 L2-norm\n",
    "\n",
    "\n",
    "- 커널 분류자는 커널 함수에 의존하여 데이터를 높은 치수 공간에 포함시키고, 여기서 비선형 관계가 선형화된다  \n",
    "\n",
    "\n",
    "- 우리는 두 가지 인기 있는 커널 함수를 선택하는데 linear kernel 과 RBF kernel이다.\n",
    "\n",
    "$$ k_{RBF}(x_i,x_j) = exp(-\\gamma\\lvert\\lvert x_i - x_j \\rvert\\rvert^2) $$\n",
    "\n",
    "- $x_i, x_j$는 두 데이터 샘플이고 $\\gamma$는 RBF 커널에 대해 가능한 출력 값의 범위를 제어하는 파라미터다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Experiments\n",
    "### 4.1 Data Set\n",
    "\n",
    "- 두 개의 동작 센서인 가속계와 자이로스코프 값을 포함하는 데이터 세트를 사용하며 세 개의 축(x, y, z)에 해당하는 각 센서에서 세 개씩 6개의 이산 신호로 구성된다. 각 신호가 약 100Hz에서 1.5초간 기록된다는 점을 감안하면 대략 150개의 값으로 표시된다.  \n",
    "\n",
    "\n",
    "- 우리는 처음 200개의 탭 이벤트에 대한 동작 신호를 수집한다. 우리는 모두 2만개의 데이터 샘플을 가지고 있다.  \n",
    "\n",
    "\n",
    "- 데이터 세트는 동일한 두 부분으로 랜덤하게 분할되며, 각 절반에는 50명의 사용자(사용자당 200개의 샘플 포함)가 포함된 데이터 세트의 첫 부분은 다급 사용자 분류 작업을 위한 신경 모델을 훈련하는 데 사용된다.\n",
    "\n",
    "\n",
    "- 우리는 사용자당 160개의 샘플을 훈련에 사용하고 나머지 40개의 샘플은 사용자당 80%~20%의 데이터 분할에 해당하는 유효성 검사를 위해 사용한다.  \n",
    "\n",
    "\n",
    "- 따라서 training 샘플은 8.000개, validation 샘플은 2.000개가 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation Metrics\n",
    "accuracy is given by: \n",
    "\n",
    "$$ ACC = \\frac{TP+TN}{TP+TN+FP+FN} $$\n",
    "\n",
    "The false acceptance rate:\n",
    "\n",
    "$$ FAR = \\frac{FP}{FP+TN}$$\n",
    "\n",
    "The false rejection rate: \n",
    "\n",
    "$$ FRR = \\frac{FN}{FN+TP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Baselines\n",
    "\n",
    "- LSTM은 RNN 모델에 영향을 미치는 것으로 알려진 기울기 소멸 문제를 해결하는 RNN 아키텍처의 한 유형이다.   \n",
    "\n",
    "\n",
    "- 우리의 세 CNN 모델에 대해서는, ConvLSTM은 다급 사용자 분류 과제에 대해 pre-trained된 다음, 사용자 식별 과제에 대한 피쳐 추출기로 사용된다.   \n",
    "\n",
    "\n",
    "- 사용자 식별 실험에서 두 기준 모델 모두 SVM 분류기를 채택하고 있는데, 이는 CNN 모델과 공정한 비교를 하기 위한 것이다.\n",
    "\n",
    "\n",
    "#### 4.3.1 Baseline based on handcrafted features\n",
    "\n",
    "\n",
    "- 주어진 사용자에게 유용한 특성을 추출하기 위해 데이터 집합에서 사용자의 일부 특수성을 포함할 수 있는 몇 가지 통계적 특징을 계산한다.   \n",
    "\n",
    "\n",
    "- 따라서 예를 구성하는 6개의 이산형 1D 신호 각각에 대해 다음과 같은 handcrafted 피쳐를 계산한다.  \n",
    "\n",
    "    • 평균 — 이산 1D 신호의 평균값  \n",
    "    • 최소 — 이산 1D 신호의 최소값  \n",
    "    • 최대 — 이산 1D 신호의 최대값  \n",
    "    • 분산 — 이산 1D 신호의 분산 값 \n",
    "    • 첨도 — 이산 1D 신호의 피크 너비  \n",
    "    • 왜도 — 이산 1D 신호의 피크 방향 \n",
    "    • 사분위수 — 30%에서 80%로 계산된 이산 1D 신호의 사분위수일 경우 10% 단계 증가 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Baseline based on ConvLSTM features\n",
    "\n",
    "-  LSTM 네트워크는 시간 입력을 직접 처리하므로 CNN 모델처럼 시간 신호를 그레이 스케일의 영상으로 변환할 필요가 없다.  \n",
    "\n",
    "\n",
    "- ConvLSTM의 아키텍처는 5개의 레이어로 구성되어 있으며, 가장 성능이 좋은 CNN 아키텍처와 크기가 유사하다.  \n",
    "\n",
    "\n",
    "    - 모델의 첫 번째 층은 32개의 필터와 1 × 3의 커널 크기를 가진 콘볼루션 LSTM 층이다. 활성화 함수로 ReLU를 사용한다. 다른 콘볼루션 LSTM 레이어가 뒤따르며, 동일한 커널 크기와 동일한 활성화 기능을 가지지만 더 많은 수의 필터(즉, 64개)를 가진다.\n",
    "    \n",
    "    - 일반적인 LSTM 아키텍처는 입력 신호의 시간적 편차를 모델링하기에 충분한 2개 이상의 LSTM 계층을 가지고 있지 않다. 따라서 두 번째 콘볼루션 LSTM 레이어 이후에는 활성화 맵이 flatten 된다. \n",
    "    \n",
    "    \n",
    "    - 128개의 뉴런으로 이루어진 완전 연결 층을 가지고 있고, 그 다음에는 256개의 뉴런으로 이루어진 완전 연결 층을 가지고 있고, 그 다음에는 ReLU 활성화가 있다.   \n",
    "    \n",
    "    \n",
    "    -  다섯 번째와 마지막 계층은 분류 계층으로, 소프트맥스 활성화가 있는 50개의 뉴런을 포함하고 있다.  \n",
    "    \n",
    "    \n",
    "    -  ConvLSTM 모델을 훈련한 후 분류 계층을 제거하고 256개의 뉴런의 마지막 완전 연결 계층에서 활성화 맵을 피쳐로 사용한다. 따라서 우리는 SVM 분류기에 입력으로 제공하는 256개의 피쳐를 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Parameter and Implementation Choices\n",
    "\n",
    "- learning rate=0.001, epoch=50 으로 training 하였으며 과적합을 방지하기 위해 early stopping을 사용하였는데 epoch=40이후 정도에 멈추었다.   \n",
    "\n",
    "\n",
    "- 드롭아웃 rate=0.4를 두 개의 완전연결층에 사용하였고, 미니 배치 사이즈로 32,64,128을 고려하였다.  \n",
    "\n",
    " \n",
    "\n",
    "![Table21912](./image/Table21912.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 256개 대신 128개 또는 512개의 기능을 생산하는 더 얇거나 더 넓은 아키텍처를 시도하여 진행한다. 여기서 우리는 256차원 피쳐 벡터를 생산하는 CNN 모델을 선택했다.  \n",
    "\n",
    "\n",
    "\n",
    "![Table31912](./image/Table31912.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RBF 커널에서 $\\gamma$ :\n",
    "\n",
    "$$ \\gamma =\\frac{1}{m*Var(X)}$$m=피쳐의 개수, X는 훈련데이터 행렬\n",
    "\n",
    "- 최적의 결과를 얻기 위해 멀티 클래스 사용자 분류 데이터 세트에서 그리드 검색을 이용하여 정규화 파라미터 C를 조정하여 SVM 모델을 조정  \n",
    "\n",
    "\n",
    "- C에 대해 가능한 값으로서 집합 {0.1, 1, 10, 100}의 값을 고려한다. RBF 커널을 사용할 때 파라미터 C의 최대값은 피쳐(handcrafted 또는 깊이)에 관계없이 100이다.   \n",
    "\n",
    "\n",
    "- 선형 커널을 사용할 때 handcrafted 피쳐의 경우 C = 100, 딥(CNN 또는 ConvLSTM) 피쳐의 경우 C = 1로 더 나은 결과를 얻었다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Multi-class User Classification Results\n",
    "\n",
    "\n",
    "- 신경망은 무게의 초기화에 민감하기 때문에 평균 결과를 보고하면서 각 모델을 5회씩 훈련시킨다.   \n",
    "\n",
    "\n",
    "![Table21912](./image/Table21912.png)\n",
    "\n",
    "- 표 2에서 구조가 깊어질수록 검증 정확도가 약간 떨어지는 경향이 있다는 점에 주목한다. \n",
    "\n",
    "\n",
    "- 우리의 훈련 데이터가 8.000개의 예들로 제한되어 있고, 학급당 160개의 샘플이 있다는 것을 고려하면, 우리는 우리의 훈련 세트 크기와 관련하여 더 깊은 네트워크가 너무 깊다는 결론을 내린다.  \n",
    "\n",
    "\n",
    "- 표 2에 제시된 경험적 결과는 32의 미니 배치 크기가 각각 6개 및 9개 계층의 CNN 아키텍처에서 최적의 값임을 나타낸다. 그러나 CNN의 12층 구조는 64개의 샘플로 구성된 미니배치로 더 나은 결과를 얻는다.   \n",
    "\n",
    "\n",
    "- 9단 CNN이 더 나은 훈련 정확도(95.88%)를 산출하는 반면, 우리 6단 CNN은 89.75%의 정확도를 보이며 일반화 능력이 더 강하다.  \n",
    "\n",
    "\n",
    "\n",
    "- 유효성 검사 세트 따라서 우리는 후속 실험을 위해 32개의 샘플로 구성된 미니배치에 기초하여 6층 CNN을 선택한다.\n",
    "\n",
    "\n",
    "- 표3에서 임베딩의 최적 크기를 결정하기 위한 추가 실험을 실시했는데 256가 검증세트에서 가장 좋은 결과를 보여줬으므로 256을 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 비슷한 방식으로, 즉 pre-trained 피쳐 추출기로서 ConvLSTM을 적용한다.\n",
    "\n",
    "![Table41912](./image/Table41912.png)\n",
    "\n",
    "- ConvLSTM(86.70%)의 검증 정확도는 우리 CNN(89.75%)의 검증 정확도보다 3.05% 낮다. 현재와 같이,우리의 CNN은 ConvLSTM보다 일반화 능력이 더 높은 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 User Identification Results\n",
    "\n",
    "![Table51912](./image/Table51912.png)\n",
    "\n",
    "- 표에서는 few-shot 사용자 식별 작업에 대한 비교 결과를 제시  \n",
    "\n",
    "\n",
    "- RBF 커널이 handcrafted 기능과 결합하여 더 나은 결과를 제공하는 반면, 선형 커널은 CNN 및 ConvLSTM과 결합하여 더 나은 결과를 제공한다는 점에 주목한다.  \n",
    "\n",
    "\n",
    "- handcrafted feature의 수(72)가 훈련 표본 수(120)보다 적기 때문에 분류 문제는 선형적으로 분리할 수 없을 가능성이 높다  \n",
    "\n",
    "\n",
    "- handcrafted feature에 기반한 SVM은 85%에서 88% 사이의 정확도를 가지고 있다.  \n",
    "\n",
    "\n",
    "- ConvLSTM 기능에 기반한 SVM은 94% ~ 95%의 정확도를 산출하고,CNN 기능에 기반한 우리의 SVM 모델은 96% ~ 97%의 정확도를 달성하며 두 기준선을 모두 능가한다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusions\n",
    "\n",
    "- 경험적 결과는 (i) 훈련 중 사용자당 20개 샘플만 사용하여 FAR 3.10%, FRR 3.45%로 96.72%의 최고 정확도를 달성하고, (ii) 시스템이 고려된 기준선에 비해 상당히 우수함을 입증한다.  \n",
    "\n",
    "\n",
    "- pre-trained CNN 기능에 기반한 SVM 모델은 등록 시 사용자로부터 20번의 탭만 필요하면서 정확도가 높은 실제 사용에 적합하다고 결론짓는다.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
